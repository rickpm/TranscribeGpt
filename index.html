<!DOCTYPE html>
<html>
  <head>
    <title>Audio Recording and Upload</title>
    <style>
      /* Add CSS styles for responsive layout */
      @media (max-width: 600px) {
        /* Adjust button size for small screens */
        button {
          padding: 10px;
          font-size: 16px;
        }
      }
    </style>
  </head>

  <body>
    <style>
      /* Add CSS styles for responsive layout */
      @media (max-width: 600px) {
        /* Adjust button size for small screens */
        button {
          padding: 10px;
          font-size: 16px;
        }
      }
    </style>
    <h1>Audio Recording and Upload to S3 Bucket</h1>
    <button id="enable-microphone">Enable Microphone</button>
    <button id="disable-microphone" disabled>Disable Microphone</button>
    <button id="start-recording" disabled>Start Recording</button>
    <button id="stop-recording" disabled>Stop Recording</button>
    <p id="transcript"></p>
    <br>
    <div id="responseContainer"></div>
    <div id="log"></div> <!-- Added log container -->

    <script src="https://cdn.webrtc-experiment.com/RecordRTC.js"></script>
    <script>
      let enableMicrophoneBtn = document.getElementById("enable-microphone");
      let disableMicrophoneBtn = document.getElementById("disable-microphone");
      let startRecordingBtn = document.getElementById("start-recording");
      let stopRecordingBtn = document.getElementById("stop-recording");
      let recorder;
      let audioStream;

      enableMicrophoneBtn.addEventListener("click", enableMicrophone);

      function enableMicrophone() {
        navigator.mediaDevices
          .getUserMedia({ audio: true })
          .then(function (stream) {
            audioStream = stream;
            enableMicrophoneBtn.disabled = true;
            disableMicrophoneBtn.disabled = false;
            startRecordingBtn.disabled = false;
            logMessage("Microphone enabled"); // Log message
          })
          .catch(function (err) {
            logError("Error enabling microphone", err); // Log error
          });
      }

      disableMicrophoneBtn.addEventListener("click", disableMicrophone);

      function disableMicrophone() {
        audioStream.getTracks().forEach((track) => track.stop());
        enableMicrophoneBtn.disabled = false;
        disableMicrophoneBtn.disabled = true;
        startRecordingBtn.disabled = true;
        stopRecordingBtn.disabled = true;
        logMessage("Microphone disabled"); // Log message
      }

      startRecordingBtn.addEventListener("click", startRecording);

      function startRecording() {
        navigator.mediaDevices
          .getUserMedia({ audio: true })
          .then(function (stream) {
            audioStream = stream;
            recorder = new RecordRTC(stream, {
              type: "audio",
              recorderType: RecordRTC.StereoAudioRecorder,
              numberOfAudioChannels: 2,
            });
            recorder.startRecording();
            startRecordingBtn.disabled = true;
            stopRecordingBtn.disabled = false;
            logMessage("Recording started"); // Log message
          })
          .catch(function (err) {
            logError("Error starting recording", err); // Log error
          });
      }

      stopRecordingBtn.addEventListener("click", stopRecording);

      function stopRecording() {
        recorder.stopRecording(function () {
          let blob = recorder.getBlob();
          uploadToS3(blob);
          recorder.reset();
          startRecordingBtn.disabled = false;
          stopRecordingBtn.disabled = true;
          logMessage("Recording stopped"); // Log message
        });
      }

      function uploadToS3(blob) {
        const fileName = "audio" + Date.now() + ".wav";
        const formData = new FormData();
        formData.append("file", blob, fileName);

        fetch("/upload", {
          method: "POST",
          body: formData,
        })
          .then(function (response) {
            logMessage("File uploaded successfully"); // Log message
            waitForTranscriptResult(fileName);
          })
          .catch(function (error) {
            logError("Error uploading file", error); // Log error
          });
      }

      function waitForTranscriptResult(
        fileName,
        retries = 3,
        interval = 15000
      ) {
        const transcriptFileName = fileName.replace(".wav", ".txt");
        const url = "/transcripts/" + transcriptFileName;

        let retryCount = 0;

        const fetchTranscript = () => {
          fetch(url)
            .then(function (response) {
              if (response.ok) {
                return response.text();
              } else {
                throw new Error("Network response was not OK");
              }
            })
            .then((result) => {
              const cleanURL = extractURLWithoutQueryParams(result);
              logMessage("Clean URL: " + cleanURL); // Log message
              getTranscriptData(cleanURL);
            })
            .catch((error) => {
              logError("Error checking transcript: ", error); // Log error

              retryCount++;
              if (retryCount < retries) {
                logMessage("Retrying in 15 seconds..."); // Log message
                setTimeout(fetchTranscript, interval);
              } else {
                logMessage(
                  "Maximum retries reached. Unable to fetch transcript."
                ); // Log message
              }
            });
        };

        setTimeout(fetchTranscript, interval);
      }

      function getTranscriptData(transcriptURL) {
        var xhr = new XMLHttpRequest();
        xhr.open("GET", transcriptURL, true);
        xhr.onreadystatechange = function () {
          try {
            if (xhr.readyState === 4) {
              if (xhr.status === 200) {
                var transcriptText = xhr.responseText;
                displayTranscript(transcriptText);
                sendToChatGPT(transcriptText);
              } else {
                throw new Error("Request failed with status " + xhr.status);
                logMessage("Request failed with status " + xhr.status); // Log message

              }
            }
          } catch (error) {
            console.error("Error processing transcript request:", error);
            logError("Error processing transcript request:", error); // Log error
          }
        };
        xhr.send();
      }
      

      function displayTranscript(text) {
        var transcriptDiv = document.getElementById("transcript");
        transcriptDiv.textContent = text;
      }

      function extractURLWithoutQueryParams(url) {
        const index = url.indexOf("?");
        if (index !== -1) {
          return url.substring(0, index);
        }
        return url;
      }

      function sendToChatGPT(transcript) {
        const prompt = transcript;
        fetch("/chat", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify({ prompt }),
        })
          .then((response) => response.json())
          .then((data) => {
            logMessage(data); // Log response data

            const generatedResponse = data.response;
            const responseContainer =
              document.querySelector("#responseContainer");
            responseContainer.innerHTML = `<p>${generatedResponse}</p>`;
          })
          .catch((error) => {
            logError("Error:", error); // Log error
          });
      }

      function logMessage(message) {
        const logContainer = document.getElementById("log");
        logContainer.innerHTML += `<p>${message}</p>`;
      }

      function logError(message, error) {
        const logContainer = document.getElementById("log");
        logContainer.innerHTML += `<p><strong>Error:</strong> ${message} - ${error}</p>`;
      }
    </script>
  </body>
</html>